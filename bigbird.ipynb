{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3f4548",
   "metadata": {},
   "source": [
    "# BigBirdModel\n",
    "\n",
    "Tokeniser: BigBirdTokenizer.pre_trained('google/bigbird-roberta-base')\n",
    "\n",
    "Model: BigBirdForQuestionAnswering\n",
    "\n",
    "Pre-trained model: [google/bigbird-roberta-base](https://huggingface.co/google/bigbird-roberta-base)\n",
    "\n",
    "Reasoning: \n",
    "BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Since the context is of very long sequences (of length more than 4096), the BigBird model which relies on block sparse attention might be more efficient and feasible than BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150fb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdb832",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6de198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "# To return a string with the contexts concatenated\n",
    "\n",
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1c9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert data into 3 lists: contexts, questions and answers respectively\n",
    "\n",
    "def read_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "      data = json.load(f)\n",
    "    \n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    for group in data:\n",
    "        contexts.append(''.join(flatten(group['context'])))\n",
    "        questions.append(group['question'])\n",
    "        answers.append(group['answer'])\n",
    "        \n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b172ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts, train_questions, train_answers = read_data('train_set.json')\n",
    "val_contexts, val_questions, val_answers = read_data('dev_set.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ff2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Bir takes in input answer_start (start index of answer in context) and answer_end (end index of answer in context).\n",
    "# Return a list of dictionaries with {text:answerstring, answer_start: start_idx, answer_end: end_idx}\n",
    "\n",
    "def update_train_answers(answers, contexts):\n",
    "    temp = []\n",
    "    for answer, context in zip(answers,contexts):\n",
    "        gold_text = answer\n",
    "        start_idx = context.find(answer)\n",
    "        # There are some yes/no answers not found in the context, hence assign them to a position outside the sequence\n",
    "        # Based on documentation: \"Position outside of the sequence are not taken into account for computing the loss.\"\n",
    "        if start_idx == -1:\n",
    "            temp.append({'text':answer, 'answer_start':len(context)+1, 'answer_end':len(context)+1})\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            temp.append({'text':answer, 'answer_start':start_idx, 'answer_end':end_idx})\n",
    "        else:\n",
    "            for n in [1,2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    temp.append({'text':answer, 'answer_start':start_idx, 'answer_end':end_idx})\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54afa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers_n = update_train_answers(train_answers,train_contexts)\n",
    "val_answers_n = update_train_answers(val_answers,val_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6f3a1",
   "metadata": {},
   "source": [
    "### Tokenize Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c198a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2e79a2885e42ad97e3ec4fc94b6b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/846k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d7832cc16f40f4a30189cc2e09c5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92940638b754470a1c9e15025271577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff28489ef6a4bebb7a0e7ef28a8ba63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BigBirdTokenizer\n",
    "\n",
    "# Tokenise input using DistilBERT tokeniser from pretrained 'distilbert-base-uncased'\n",
    "tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_contexts, train_questions,train_answers, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, val_answers, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a55637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the start and end position tokens which is required for the BigBirdForQuestionAnswering model\n",
    "def add_token_answers(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i,answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i,answers[i]['answer_end']))\n",
    "        \n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        # end position cannot be found, char_to_token found space, so shift one token forward\n",
    "        go_back = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end']-go_back)\n",
    "            go_back +=1\n",
    "    encodings.update({\n",
    "        'start_positions':start_positions,\n",
    "        'end_positions':end_positions\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa338561",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token_answers(train_encodings,train_answers_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ebe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token_answers(val_encodings,val_answers_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class NLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = NLDataset(train_encodings)\n",
    "val_dataset = NLDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c48bf",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7603b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BigBirdForQuestionAnswering\n",
    "\n",
    "# Initialising the BigBirdForQuestionAnswering model using pre-trained 'google/bigbird-roberta-base'\n",
    "model = BigBirdForQuestionAnswering.from_pretrained('google/bigbird-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ae115c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f0b0044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')# move model over to detected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e0954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 12/5653 [02:30<18:23:10, 11.73s/it, loss=5.38]"
     ]
    }
   ],
   "source": [
    "# activate training mode of model\n",
    "model.train()\n",
    "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# initialize data loader for training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "    # setup loop (we use tqdm for the progress bar)\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all the tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        # train model on batch and return outputs (incl. loss)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        # extract loss\n",
    "        loss = outputs[0]\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/bigbird-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch model out of training mode\n",
    "model.eval()\n",
    "\n",
    "#val_sampler = SequentialSampler(val_dataset)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "acc = []\n",
    "\n",
    "# initialize loop for progress bar\n",
    "loop = tqdm(val_loader)\n",
    "# loop through batches\n",
    "for batch in loop:\n",
    "    # we don't need to calculate gradients as we're not training\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    with torch.no_grad():\n",
    "        # pull batched items from loader\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        # make predictions\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # pull preds out\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate ACCURACY\n",
    "        # calculate accuracy for both and append to accuracy list\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "        \n",
    "        # Calculate F1\n",
    "        # calculate True Positive, False Negative and False Positive\n",
    "        for i in range(len(start_pred)):\n",
    "            x = range(start_pred[i],end_pred[i])\n",
    "            y = range(start_true[i],end_true[i])\n",
    "\n",
    "            xs = set(x)\n",
    "            ys = set(y)\n",
    "            tp = len(xs&ys)\n",
    "            fp = len(xs-ys)\n",
    "            fn = len(ys-xs)\n",
    "            total_tp += tp\n",
    "            total_fp += fp\n",
    "            total_fn += fn\n",
    "        \n",
    "# calculate average accuracy in total\n",
    "acc = sum(acc)/len(acc)\n",
    "precision = total_tp/(total_tp+total_fp)\n",
    "recall=total_tp/(total_tp+total_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T/F\\tstart\\tend\\n\")\n",
    "for i in range(len(start_true)):\n",
    "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
    "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe59147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(recall)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f17e7e",
   "metadata": {},
   "source": [
    "### Load Pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigBirdForQuestionAnswering.from_pretrained('models/bigbird-custom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f77cca",
   "metadata": {},
   "source": [
    "### Results\n",
    "Accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cfdff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
